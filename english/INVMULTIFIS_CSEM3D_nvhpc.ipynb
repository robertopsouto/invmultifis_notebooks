{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertopsouto/invmultifis_notebooks/blob/main/english/INVMULTIFIS_CSEM3D_nvhpc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INVMULTIFIS Project: Development of multi-physics data inversion software with optimization via artificial intelligence**\n",
        "\n",
        "The project proposes the development of an innovative inversion technology for the characterization and monitoring of deep water reservoirs for Petrobras (the Brazilian Oil Company) using CSEM (Controlled-Source Electromagnetic Methods), a robust risk reduction tool in the drilling of oil basins, using multiphysics data in the 3D domain. One of the main objectives of this project is to develop, optimize and parallelize CSEM codes, aiming at improving their performance. "
      ],
      "metadata": {
        "id": "ND2kYHItEyQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Donwload and install NVIDIA HPC SDK"
      ],
      "metadata": {
        "id": "n8mICxHdmRKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Downloading and installing deb packages. This will take 5 minutes.\n",
        "! curl https://developer.download.nvidia.com/hpc-sdk/ubuntu/DEB-GPG-KEY-NVIDIA-HPC-SDK | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-hpcsdk-archive-keyring.gpg\n",
        "! echo 'deb [signed-by=/usr/share/keyrings/nvidia-hpcsdk-archive-keyring.gpg] https://developer.download.nvidia.com/hpc-sdk/ubuntu/amd64 /' | sudo tee /etc/apt/sources.list.d/nvhpc.list\n",
        "! sudo apt-get update -y\n",
        "! sudo apt-get install -y nvhpc-22-11"
      ],
      "metadata": {
        "id": "iv_6sBm1vZ6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install `environment-modules` package to load `nvhpc`"
      ],
      "metadata": {
        "id": "Qu9UwS4Pme8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "apt install environment-modules"
      ],
      "metadata": {
        "id": "F0CRfGnjvgyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading `nvhpc` and run `nvaccelinfo` command"
      ],
      "metadata": {
        "id": "ffug2Yfkmuug"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcphTrlvvJkH"
      },
      "source": [
        "---\n",
        "Let's execute the cell below to display information about the GPUs running on the server by running the `nvaccelinfo` command, which ships with the NVIDIA HPC compiler that we will be using. To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see some output returned below the grey cell."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "nvaccelinfo"
      ],
      "metadata": {
        "id": "1Z_6ReluxYdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dDXsd4rvJkJ"
      },
      "source": [
        "The output of the above command will vary according to which GPUs you have in your system. For example, if you are running the lab on a machine with NVIDIA Tesla V100 GPUs, you might would see the following:\n",
        "\n",
        "```\n",
        "CUDA Driver Version:           10010\n",
        "NVRM version:                  NVIDIA UNIX x86_64 Kernel Module  418.87.01  Wed Sep 25 06:00:38 UTC 2019\n",
        "\n",
        "Device Number:                 0\n",
        "Device Name:                   Tesla V100-SXM2-16GB\n",
        "Device Revision Number:        7.0\n",
        "Global Memory Size:            16914055168\n",
        "Number of Multiprocessors:     80\n",
        "Concurrent Copy and Execution: Yes\n",
        "Total Constant Memory:         65536\n",
        "Total Shared Memory per Block: 49152\n",
        "Registers per Block:           65536\n",
        "Warp Size:                     32\n",
        "Maximum Threads per Block:     1024\n",
        "Maximum Block Dimensions:      1024, 1024, 64\n",
        "Maximum Grid Dimensions:       2147483647 x 65535 x 65535\n",
        "Maximum Memory Pitch:          2147483647B\n",
        "Texture Alignment:             512B\n",
        "Clock Rate:                    1530 MHz\n",
        "Execution Timeout:             No\n",
        "Integrated Device:             No\n",
        "Can Map Host Memory:           Yes\n",
        "Compute Mode:                  default\n",
        "Concurrent Kernels:            Yes\n",
        "ECC Enabled:                   Yes\n",
        "Memory Clock Rate:             877 MHz\n",
        "Memory Bus Width:              4096 bits\n",
        "L2 Cache Size:                 6291456 bytes\n",
        "Max Threads Per SMP:           2048\n",
        "Async Engines:                 6\n",
        "Unified Addressing:            Yes\n",
        "Managed Memory:                Yes\n",
        "Concurrent Managed Memory:     Yes\n",
        "Preemption Supported:          Yes\n",
        "Cooperative Launch:            Yes\n",
        "  Multi-Device:                Yes\n",
        "Default Target:            -ta=tesla:cc70\n",
        "```\n",
        "\n",
        "This gives us lots of details about the GPU, for instance the device number, the type of device, and at the very bottom the command line argument we should use when targeting this GPU (see *_NVIDIA HPC Compiler Option_*). We will use this command line option a bit later to build for our GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps to install CSEM3D program"
      ],
      "metadata": {
        "id": "kmLuqCjxcuSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing GNU Make v4.3 to correct deal with CSEM3D `makefile`"
      ],
      "metadata": {
        "id": "8tYlZFTsgWUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wget https://ftp.gnu.org/gnu/make/make-4.3.tar.gz\n",
        "tar xfz make-4.3.tar.gz"
      ],
      "metadata": {
        "id": "6HlBN7NR61Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd make-4.3\n",
        "./configure\n",
        "make\n",
        "make install"
      ],
      "metadata": {
        "id": "Wypy9Zi3AKYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "make -v"
      ],
      "metadata": {
        "id": "-y-pfI7whQPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Creating user, once OpenMPI does not recommend run MPI with `root` user\n",
        "\n"
      ],
      "metadata": {
        "id": "ZauSBltE7BRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "adduser csem"
      ],
      "metadata": {
        "id": "OpsXjBevpynC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PETSC v3.18.4"
      ],
      "metadata": {
        "id": "_T7fMY7E-_yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download, extract the source code file and run `configure` file"
      ],
      "metadata": {
        "id": "7f14F4LpkoAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "mkdir -p ${HOME}/petsc/nvhpc\n",
        "cd ${HOME}/petsc/nvhpc\n",
        "wget https://gitlab.com/petsc/petsc/-/archive/v3.18.4/petsc-v3.18.4.tar.gz\n",
        "tar zxvf petsc-v3.18.4.tar.gz\n",
        "cd petsc-v3.18.4\n",
        "./configure \\\n",
        " --prefix=${PWD}/installdir \\\n",
        " --with-fortran \\\n",
        " --with-fortran-kernels=true \\\n",
        " --with-cuda \\\n",
        " --download-fblaslapack \\\n",
        " --with-scalar-type=complex \\\n",
        " --with-precision=double \\\n",
        " --with-debugging=0 \\\n",
        " --with-x=0 \\\n",
        " --with-cc=mpicc \\\n",
        " --with-cxx=mpicxx \\\n",
        " --with-fc=mpif90 \\\n",
        " --with-make-exec=make \\\n",
        " 2>&1 | tee ../configure.out"
      ],
      "metadata": {
        "id": "RoiHpJRYghSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run `make all` phase. \n",
        "```bash\n",
        "If it is successfully finished, this message must appear:\n",
        "\n",
        "=========================================\n",
        "Now to install the libraries do:\n",
        "make PETSC_DIR=/home/csem/petsc/nvhpc/petsc-v3.18.4 PETSC_ARCH=arch-linux-c-opt install\n",
        "=========================================\n",
        "```"
      ],
      "metadata": {
        "id": "tKQfmqxN8XYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4\n",
        "make PETSC_DIR=/home/csem/petsc/nvhpc/petsc-v3.18.4 PETSC_ARCH=arch-linux-c-opt all"
      ],
      "metadata": {
        "id": "l77hzqGPU9o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run `make install` phase\n",
        "```bash\n",
        "If it is successfully finished, this message must appear:\n",
        "\n",
        "====================================\n",
        "Install complete.\n",
        "Now to check if the libraries are working do (in current directory):\n",
        "make PETSC_DIR=/home/csem/petsc/nvhpc/petsc-v3.18.4/installdir PETSC_ARCH=\"\" check\n",
        "====================================\n",
        "```"
      ],
      "metadata": {
        "id": "8D-wCIYI9tgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4\n",
        "make PETSC_DIR=/home/csem/petsc/nvhpc/petsc-v3.18.4 PETSC_ARCH=arch-linux-c-opt install"
      ],
      "metadata": {
        "id": "quwqTfSiougo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run `make check` phase\n",
        "```bash\n",
        "If it is successfully finished, this message must appear:\n",
        "\n",
        "Running check examples to verify correct installation\n",
        "Using PETSC_DIR=/home/csem/petsc/nvhpc/petsc-v3.18.4/installdir and PETSC_ARCH=\n",
        "C/C++ example src/snes/tutorials/ex19 run successfully with 1 MPI process\n",
        "C/C++ example src/snes/tutorials/ex19 run successfully with 2 MPI processes\n",
        "C/C++ example src/snes/tutorials/ex19 run successfully with cuda\n",
        "Fortran example src/snes/tutorials/ex5f run successfully with 1 MPI process\n",
        "Completed test examples\n",
        "```"
      ],
      "metadata": {
        "id": "2Yt-DGeJ-UTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4\n",
        "make PETSC_DIR=/home/csem/petsc/nvhpc/petsc-v3.18.4/installdir PETSC_ARCH=\"\" check"
      ],
      "metadata": {
        "id": "trURj4-HpH5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test an example performing complex numbers (`ex11f.F90`)"
      ],
      "metadata": {
        "id": "7mk78mlItJGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4/src/ksp/ksp/tutorials\n",
        "make ex11f\n",
        "mpirun -n 1 ./ex11f -norandom -pc_type none -ksp_monitor_short -ksp_gmres_cgs_refinement_type refine_always"
      ],
      "metadata": {
        "id": "ckgggNZ2jJI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check with reference output (`output/ex11f_1.out`)"
      ],
      "metadata": {
        "id": "3Ybo2a-eu1ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4/src/ksp/ksp/tutorials\n",
        "cat output/ex11f_1.out"
      ],
      "metadata": {
        "id": "dWgJ8b6Oupva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Following instructions in https://petsc.org/release/developers/testing/ to run an example that requires CUDA."
      ],
      "metadata": {
        "id": "7aywCjpyC5Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4/\n",
        "make print-test query='suffix' queryval='2_aijcusparse'"
      ],
      "metadata": {
        "id": "7yZsTeL36oGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4/\n",
        "make test search=ksp_ksp_tutorials-ex1_2_aijcusparse"
      ],
      "metadata": {
        "id": "vDjjGJof68oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4/\n",
        "cat arch-linux-c-opt/tests/ksp/ksp/tutorials/runex1_2_aijcusparse/ksp_ksp_tutorials-ex1_2_aijcusparse.sh"
      ],
      "metadata": {
        "id": "jfJg6dB_7aTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4/\n",
        "cd src/ksp/ksp/tutorials/\n",
        "make ex1\n",
        "mpiexec --oversubscribe  -n 1  ./ex1 \\\n",
        "-petsc_ci \\\n",
        "-pc_type sor \\\n",
        "-pc_sor_symmetric \\\n",
        "-ksp_monitor_short \\\n",
        "-ksp_gmres_cgs_refinement_type refine_always \\\n",
        "-mat_type aijcusparse \\\n",
        "-vec_type cuda \\\n",
        "-use_gpu_aware_mpi 0\n"
      ],
      "metadata": {
        "id": "CX6DBBNz92No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If it is successfully finished, this output must appear:\n",
        "```bash\n",
        "  0 KSP Residual norm 0.968764 \n",
        "  1 KSP Residual norm 0.361001 \n",
        "  2 KSP Residual norm 0.247329 \n",
        "  3 KSP Residual norm 0.0808915 \n",
        "  4 KSP Residual norm 0.01289 \n",
        "  5 KSP Residual norm 0.00375064 \n",
        "  6 KSP Residual norm 0.000294092 \n",
        "  7 KSP Residual norm 1.40861e-05 \n",
        "  8 KSP Residual norm 3.48863e-07 \n",
        "KSP Object: 1 MPI process\n",
        "  type: gmres\n",
        "    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with one step of iterative refinement\n",
        "    happy breakdown tolerance 1e-30\n",
        "  maximum iterations=10000, initial guess is zero\n",
        "  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.\n",
        "  left preconditioning\n",
        "  using PRECONDITIONED norm type for convergence test\n",
        "PC Object: 1 MPI process\n",
        "  type: sor\n",
        "    type = symmetric, iterations = 1, local iterations = 1, omega = 1.\n",
        "  linear system matrix = precond matrix:\n",
        "  Mat Object: 1 MPI process\n",
        "    type: seqaijcusparse\n",
        "    rows=10, cols=10\n",
        "    total: nonzeros=28, allocated nonzeros=28\n",
        "    total number of mallocs used during MatSetValues calls=0\n",
        "      not using I-node routines\n",
        "Norm of error 4.10316e-07, Iterations 8\n",
        "  0 KSP Residual norm 0.377523 \n",
        "  1 KSP Residual norm 0.0140399 \n",
        "  2 KSP Residual norm 0.000364106 \n",
        "  3 KSP Residual norm 7.83047e-06 \n",
        "  4 KSP Residual norm 1.33045e-07 \n",
        "\n",
        "  ```"
      ],
      "metadata": {
        "id": "79nGc6nQ-81m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4/\n",
        "cd src/ksp/ksp/tutorials/\n",
        "cat output/ex1_2_aijcusparse.out"
      ],
      "metadata": {
        "id": "iJBKyQbw_6F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Profiling with `nvprof`"
      ],
      "metadata": {
        "id": "JaBACE2t8kd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4/\n",
        "cd src/ksp/ksp/tutorials/\n",
        "make ex1\n",
        "mpiexec --oversubscribe  -n 1 nvprof -f -o ex1.%q{OMPI_COMM_WORLD_RANK}.nvprof ./ex1 \\\n",
        "-petsc_ci \\\n",
        "-pc_type sor \\\n",
        "-pc_sor_symmetric \\\n",
        "-ksp_monitor_short \\\n",
        "-ksp_gmres_cgs_refinement_type refine_always \\\n",
        "-mat_type aijcusparse \\\n",
        "-vec_type cuda"
      ],
      "metadata": {
        "id": "hLbP8yvaBP_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show profiling obtained with `nvprof`"
      ],
      "metadata": {
        "id": "VcBVWEFH8rD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/petsc/nvhpc/petsc-v3.18.4/\n",
        "cd src/ksp/ksp/tutorials/\n",
        "nvprof -i ex1.0.nvprof"
      ],
      "metadata": {
        "id": "wKptcSvmCP8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `CSEM3D` program"
      ],
      "metadata": {
        "id": "x7i-RDy0_OcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the source code files of `CSEM3D` program in the `root` area."
      ],
      "metadata": {
        "id": "HesBtLZL_h4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1iNGEZIM8Whd1mRmfA2HekxBII5OXVcZ_' -O csem3d_w-v1.0.3.tar.gz"
      ],
      "metadata": {
        "id": "PrcUfF1Dlz8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "ls csem3d_w-v1.0.3.tar.gz -lh"
      ],
      "metadata": {
        "id": "0sPHelSvzLYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy the tarball file to `csem` user account area, and change the onwer of this file to `csem` user."
      ],
      "metadata": {
        "id": "7UCV-R5fARWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cp csem3d_w-v1.0.3.tar.gz /home/csem/\n",
        "chown csem:csem /home/csem/csem3d_w-v1.0.3.tar.gz"
      ],
      "metadata": {
        "id": "ZttctxX4lfBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unpacking the tarball file"
      ],
      "metadata": {
        "id": "Nuz-Z1RRA9Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "cd /home/csem\n",
        "tar zxvf csem3d_w-v1.0.3.tar.gz"
      ],
      "metadata": {
        "id": "k0b5ZF1imGY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run `make all` to install the `CSEM3D` program\n",
        "```bash\n",
        "If it is successfully finished, this message must appear:\n",
        "\n",
        "mpif90 -o CSEM3D_W outfields_E_Tx.o spline.o bottom.o allvars.o intpol1.o biprho.o dimped.o in3dmod.o compute_src_wts.o set_resist_vector.o locals.o kinds.o outfields_B_Tx.o B_Tx_B_Rx.o dimens.o set_P.o set_bv_e.o d1imped.o set_src.o grid.o in3drho.o CSEM3D_mod.o CSEM3D_W.o set_bv_h.o bipole2.o set_A.o chk_rx_tx.o set_1d_resist.o txrx.o splint.o set_rhs.o blocks.o E_Tx_E_Rx.o convres.o abs_to_rel.o B_Tx_E_Rx.o E_Tx_B_Rx.o addair.o -L/home/csem/petsc/gnu/petsc-v3.18.4/installdir/lib -lpetsc  \n",
        "```"
      ],
      "metadata": {
        "id": "LriJdUisBJKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/csem3d_w-v1.0.3/CSEM3D_W/CSEM3D_W\n",
        "make PETSC_DIR=${HOME}/petsc/nvhpc/petsc-v3.18.4/installdir -f scripts/makefile_nvhpc clean"
      ],
      "metadata": {
        "id": "cflx5G_EoLl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "cd /home/csem/csem3d_w-v1.0.3/CSEM3D_W/CSEM3D_W\n",
        "make PETSC_DIR=${HOME}/petsc/nvhpc/petsc-v3.18.4/installdir -f scripts/makefile_nvhpc all"
      ],
      "metadata": {
        "id": "-sBQCQXapf4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run this bash `script` to execute the generated `CSEM3D_W` binary file.\n",
        "\n",
        "```bash\n",
        "If it is successfully finished, a similar message like below must appear:\n",
        "\n",
        " 16 KSP preconditioned resid norm 3.863008301354e-18 true resid norm 1.284864871592e-05 ||r(i)||/||b|| 3.405644702963e-01\n",
        " 17 KSP preconditioned resid norm 2.061402843466e-18 true resid norm 1.054741071689e-05 ||r(i)||/||b|| 2.795681805313e-01\n",
        " 18 KSP preconditioned resid norm 1.062033155132e-18 true resid norm 3.992776343547e-06 ||r(i)||/||b|| 1.058319664983e-01\n",
        " converged reason            2\n",
        " total number of relaxations           18\n",
        " ========================================\n",
        "\n",
        " \n",
        " ************************************************\n",
        "  3D finished\n",
        "  Total CPU time:    18.7500000      seconds\n",
        " ************************************************\n",
        " \n",
        " total cpu time:    18.7500000      seconds\n",
        " CSEM3D_W finished\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "hRhpojxUB_xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "\n",
        "cd /home/csem/csem3d_w-v1.0.3/CSEM3D_W/CSEM3D_W\n",
        "\n",
        "PETSC_DIR=${HOME}/petsc/nvhpc/petsc-v3.18.4/installdir\n",
        "\n",
        "dataset=Sintetico\n",
        "ntasks=1\n",
        "nnodes=1\n",
        "\n",
        "TIMESTART=$(date +%Y%m%d%H%M%S)\n",
        "\n",
        "if [[ -L ${dataset} ]]\n",
        "then\n",
        "    echo \"Link j치 existe para o dataset ${dataset}\"\n",
        "else\n",
        "    ln -s dataset/${dataset}\n",
        "fi\n",
        "sed 's/\\.\\//'${dataset}'\\//g' ${dataset}/Parameters.inp | \\\n",
        "sed 's/'${dataset}'\\/OutData/OutData/g' > Parameters.inp\n",
        "\n",
        "outputdir=\"OutData\"\n",
        "if [[ -d ${outputdir} ]]\n",
        "then\n",
        "    echo \"OutData j치 existe.\"\n",
        "    rm -fr ${outputdir}\n",
        "fi\n",
        "mkdir ${outputdir}\n",
        "\n",
        "\n",
        "resultsdir=results/${dataset}/NUMNODES-${nnodes}/MPI-${ntasks}/EXECSTART-${TIMESTART}\n",
        "mkdir -p ${resultsdir}\n",
        "\n",
        "export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${PETSC_DIR}/lib\n",
        "\n",
        "executable=CSEM3D_W\n",
        "\n",
        "echo \"mpirun -np $ntasks ./${executable}\"\n",
        "mpirun -np $ntasks ./${executable} \\\n",
        " -A_mat_type mpiaij \\\n",
        " -P_mat_type mpiaij \\\n",
        " -em_ksp_monitor_true_residual \\\n",
        " -em_ksp_type bcgs \\\n",
        " -em_pc_type bjacobi \\\n",
        " -em_sub_pc_type ilu \\\n",
        " -em_sub_pc_factor_levels 3 \\\n",
        " -em_sub_pc_factor_fill 6 \\\n",
        " < ./Parameters.inp \\\n",
        " 2>&1 | tee csem3d_w-${TIMESTART}.out\n",
        "\n",
        "mv $outputdir/ ${resultsdir}/\n",
        "cp csem3d_w-${TIMESTART}.out ${resultsdir}/\n"
      ],
      "metadata": {
        "id": "t83IHP-iZd-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "su csem\n",
        "source /usr/share/modules/init/bash\n",
        "module use /opt/nvidia/hpc_sdk/modulefiles\n",
        "module load nvhpc/22.11\n",
        "\n",
        "cd /home/csem/csem3d_w-v1.0.3/CSEM3D_W/CSEM3D_W\n",
        "\n",
        "PETSC_DIR=${HOME}/petsc/nvhpc/petsc-v3.18.4/installdir\n",
        "\n",
        "\n",
        "dataset=Sintetico\n",
        "ntasks=1\n",
        "nnodes=1\n",
        "\n",
        "TIMESTART=$(date +%Y%m%d%H%M%S)\n",
        "\n",
        "if [[ -L ${dataset} ]]\n",
        "then\n",
        "    echo \"Link j치 existe para o dataset ${dataset}\"\n",
        "else\n",
        "    ln -s dataset/${dataset}\n",
        "fi\n",
        "sed 's/\\.\\//'${dataset}'\\//g' ${dataset}/Parameters.inp | \\\n",
        "sed 's/'${dataset}'\\/OutData/OutData/g' > Parameters.inp\n",
        "\n",
        "outputdir=\"OutData\"\n",
        "if [[ -d ${outputdir} ]]\n",
        "then\n",
        "    echo \"OutData j치 existe.\"\n",
        "    rm -fr ${outputdir}\n",
        "fi\n",
        "mkdir ${outputdir}\n",
        "\n",
        "\n",
        "resultsdir=results/${dataset}/NUMNODES-${nnodes}/MPI-${ntasks}/EXECSTART-${TIMESTART}\n",
        "mkdir -p ${resultsdir}\n",
        "\n",
        "export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${PETSC_DIR}/lib\n",
        "\n",
        "executable=CSEM3D_W\n",
        "\n",
        "echo \"mpirun -np $ntasks nvprof -f -o ${executable}.%q{OMPI_COMM_WORLD_RANK}.nvprof ./${executable}\"\n",
        "mpirun -np $ntasks nvprof -f -o ${executable}.%q{OMPI_COMM_WORLD_RANK}.nvprof ./${executable} \\\n",
        " -A_mat_type aijcusparse \\\n",
        " -P_mat_type aijcusparse \\\n",
        " -vec_type cuda \\\n",
        " -use_gpu_aware_mpi 0 \\\n",
        " -em_ksp_monitor_true_residual \\\n",
        " -em_ksp_type bcgs \\\n",
        " -em_pc_type bjacobi \\\n",
        " -em_sub_pc_type ilu \\\n",
        " -em_sub_pc_factor_levels 3 \\\n",
        " -em_sub_pc_factor_fill 6 \\\n",
        " < ./Parameters.inp \\\n",
        " 2>&1 | tee csem3d_w-${TIMESTART}.out\n",
        "\n",
        "mv $outputdir/ ${resultsdir}/\n",
        "cp csem3d_w-${TIMESTART}.out ${resultsdir}/"
      ],
      "metadata": {
        "id": "-i2uvTwR1MhC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}